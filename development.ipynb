{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8bb6b0-4124-4cf0-b807-d6ed468b3b07",
   "metadata": {},
   "source": [
    "# Size Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81966c-59f5-48b1-82e7-df70eec8be82",
   "metadata": {},
   "source": [
    "## Loading input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c639116e-1991-46b5-8b62-39958df0ddee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:39:36.057655Z",
     "iopub.status.busy": "2023-08-01T07:39:36.057067Z",
     "iopub.status.idle": "2023-08-01T07:39:36.984678Z",
     "shell.execute_reply": "2023-08-01T07:39:36.983764Z",
     "shell.execute_reply.started": "2023-08-01T07:39:36.057521Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cuff_train: (10712, 3), x_cuff_test: (2678, 3)\n",
      "x_uncuff_train: (18934, 3), x_uncuff_test: (4733, 3)\n"
     ]
    }
   ],
   "source": [
    "import pickle, os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Load the dataset\n",
    "df = pickle.load(open('dataset/df_2308', 'rb'))\n",
    "\n",
    "# Sort the data in ascending order based on the 'opdate' column (most recent first)\n",
    "df.sort_values(by=['opdate'], ascending=True, inplace=True)\n",
    "\n",
    "# Extract features (x) and target (y) values from the dataFrame\n",
    "x = df[['age_cal', 'sex', 'weight', 'height', 'cuffed']].astype(float).values\n",
    "y = df['airway_tube_size'].astype(float).values\n",
    "c = df['opid'].values\n",
    "\n",
    "# Separate the data for cuffed and uncuffed endotracheal tubes\n",
    "## Cuffed endotrahceal tube\n",
    "x_cuffed = x[x[:, 4] == 1][:, :3]\n",
    "y_cuffed = y[x[:, 4] == 1]\n",
    "\n",
    "# Determine the size of the test and train sets for cuffed data\n",
    "nsamp = len(y_cuffed)\n",
    "ntest = int(nsamp * 0.2)\n",
    "ntrain = nsamp - ntest\n",
    "\n",
    "# Split the cuffed data into training and test sets\n",
    "x_cuff_test = x_cuffed[-ntest:, :]\n",
    "y_cuff_test = y_cuffed[-ntest:]\n",
    "x_cuff_train = x_cuffed[:ntrain, :]\n",
    "y_cuff_train = y_cuffed[:ntrain]\n",
    "\n",
    "# Impute missing values in the cuffed data using the multiple imputation method\n",
    "imp = IterativeImputer().fit(x_cuff_train)\n",
    "x_cuff_train = imp.transform(x_cuff_train)\n",
    "x_cuff_test = imp.transform(x_cuff_test)\n",
    "\n",
    "## Uncuffed endotracheal tube\n",
    "x_uncuffed = x[x[:, 4] == 0][:, :3]\n",
    "y_uncuffed = y[x[:, 4] == 0]\n",
    "\n",
    "# Determine the size of the test and train sets for uncuffed data\n",
    "nsamp = len(y_uncuffed)\n",
    "ntest = int(nsamp * 0.2)\n",
    "ntrain = nsamp - ntest\n",
    "\n",
    "# Split the uncuffed data into training and test sets\n",
    "x_uncuff_test = x_uncuffed[-ntest:, :]\n",
    "y_uncuff_test = y_uncuffed[-ntest:]\n",
    "x_uncuff_train = x_uncuffed[:ntrain, :]\n",
    "y_uncuff_train = y_uncuffed[:ntrain]\n",
    "\n",
    "# Impute missing values in the uncuffed data using the multiple imputation method\n",
    "imp = IterativeImputer().fit(x_uncuff_train)\n",
    "x_uncuff_train = imp.transform(x_uncuff_train)\n",
    "x_uncuff_test = imp.transform(x_uncuff_test)\n",
    "\n",
    "# Print the shapes of the cuffed and uncuffed training and test sets\n",
    "print(f'x_cuff_train: {(x_cuff_train).shape}, x_cuff_test: {x_cuff_test.shape}')\n",
    "print(f'x_uncuff_train: {(x_uncuff_train).shape}, x_uncuff_test: {x_uncuff_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277516c0-a243-4d55-be86-ba9b5b5d29cd",
   "metadata": {},
   "source": [
    "## Feature Selection (BorutaShap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a524a-7785-4ec2-af0c-a05648a9c3eb",
   "metadata": {},
   "source": [
    "### Cuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffde77-3bd8-4118-a183-1f3029166504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:39:21.927095Z",
     "iopub.status.busy": "2023-08-01T07:39:21.926625Z",
     "iopub.status.idle": "2023-08-01T07:39:22.079208Z",
     "shell.execute_reply": "2023-08-01T07:39:22.077789Z",
     "shell.execute_reply.started": "2023-08-01T07:39:21.927045Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "# Define the input variables (features) and target variable (label)\n",
    "INPUT_VARS = ['age', 'sex', 'weight', 'height']\n",
    "TARGET_VAR = 'airway_tube_size'\n",
    "\n",
    "# Create a DataFrame with the training features (X) from the cuffed data\n",
    "X = pd.DataFrame(x_cuff_train, columns=INPUT_VARS)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "SEED = 98\n",
    "\n",
    "# Create an XGBoost Regressor model\n",
    "xgbr = xgb.XGBRegressor()\n",
    "\n",
    "# Initialize the BorutaShap feature selector\n",
    "Feature_Selector = BorutaShap(model=xgbr, \n",
    "                              importance_measure='shap', \n",
    "                              classification=False, \n",
    "                              percentile=100, \n",
    "                              pvalue=0.05)\n",
    "\n",
    "# Fit the feature selector to the data\n",
    "Feature_Selector.fit(X=X, \n",
    "                     y=y_cuff_train, \n",
    "                     n_trials=100, \n",
    "                     sample=False, \n",
    "                     train_or_test='train', \n",
    "                     normalize=True, \n",
    "                     verbose=True, \n",
    "                     random_state=SEED)\n",
    "\n",
    "# Plot the results of the BorutaShap feature selection\n",
    "Feature_Selector.plot(X_size=10,\n",
    "                       which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48af4b2-4de9-4274-b372-506bff112a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:39:40.048458Z",
     "iopub.status.busy": "2023-08-01T07:39:40.048102Z",
     "iopub.status.idle": "2023-08-01T07:39:40.053090Z",
     "shell.execute_reply": "2023-08-01T07:39:40.052231Z",
     "shell.execute_reply.started": "2023-08-01T07:39:40.048428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exclude the 'sex' feature and concatenate 'age', 'weight', and 'height' features into a new feature set\n",
    "x_cuff_train = np.concatenate((x_cuff_train[:,0:1], x_cuff_train[:,2:4]),axis=-1)\n",
    "x_cuff_test = np.concatenate((x_cuff_test[:,0:1], x_cuff_test[:,2:4]),axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e33189-fd25-4515-a58d-8050a2e27ea9",
   "metadata": {},
   "source": [
    "### Uncuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3556d14-38ea-4c70-9d14-adc3cb30eaed",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-01T07:39:22.081716Z",
     "iopub.status.idle": "2023-08-01T07:39:22.082238Z",
     "shell.execute_reply": "2023-08-01T07:39:22.082053Z",
     "shell.execute_reply.started": "2023-08-01T07:39:22.082030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "# Define the input variables (features) and target variable (label)\n",
    "INPUT_VARS = ['age', 'sex', 'weight', 'height']\n",
    "TARGET_VAR = 'airway_tube_size'\n",
    "\n",
    "# Create a DataFrame with the training features (X) from the uncuffed data\n",
    "X = pd.DataFrame(x_uncuff_train, columns=INPUT_VARS)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "SEED = 98\n",
    "\n",
    "# Create an XGBoost Regressor model\n",
    "xgbr = xgb.XGBRegressor()\n",
    "\n",
    "# Initialize the BorutaShap feature selector\n",
    "Feature_Selector = BorutaShap(model=xgbr, \n",
    "                              importance_measure='shap', \n",
    "                              classification=False, \n",
    "                              percentile=100, \n",
    "                              pvalue=0.05)\n",
    "\n",
    "# Fit the feature selector to the data\n",
    "Feature_Selector.fit(X=X, \n",
    "                     y=y_uncuff_train, \n",
    "                     n_trials=100, \n",
    "                     sample=False, \n",
    "                     train_or_test='train', \n",
    "                     normalize=True, \n",
    "                     verbose=True, \n",
    "                     random_state=SEED)\n",
    "\n",
    "# Plot the results of the BorutaShap feature selection\n",
    "Feature_Selector.plot(X_size=10,\n",
    "                       which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbce1393-7695-41de-8bf7-052c0912eb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:39:42.333971Z",
     "iopub.status.busy": "2023-08-01T07:39:42.333451Z",
     "iopub.status.idle": "2023-08-01T07:39:42.340839Z",
     "shell.execute_reply": "2023-08-01T07:39:42.339555Z",
     "shell.execute_reply.started": "2023-08-01T07:39:42.333921Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exclude the 'sex' feature and concatenate 'age', 'weight', and 'height' features into a new feature set\n",
    "x_uncuff_train = np.concatenate((x_uncuff_train[:,0:1], x_uncuff_train[:,2:4]),axis=-1)\n",
    "x_uncuff_test = np.concatenate((x_uncuff_test[:,0:1], x_uncuff_test[:,2:4]),axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b003b-230c-4989-ab0d-066415d6e259",
   "metadata": {},
   "source": [
    "## Traditional Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf27131-c775-48b0-adec-4fb1b074b7bc",
   "metadata": {},
   "source": [
    "### Cuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0758d265-fbab-45f6-a4bd-d28862e596b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:39:44.656837Z",
     "iopub.status.busy": "2023-08-01T07:39:44.656105Z",
     "iopub.status.idle": "2023-08-01T07:41:34.336186Z",
     "shell.execute_reply": "2023-08-01T07:41:34.335497Z",
     "shell.execute_reply.started": "2023-08-01T07:39:44.656788Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traditional formula for cuffed ETT (Duracher)\n",
      "acc: 0.469+-0.010, 95% CI 0.453-0.485\n",
      "acc within 0.5mm: 0.966+-0.003, 95% CI 0.960-0.972\n",
      "macro f1: 0.391+-0.009, 95% CI 0.377-0.405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Traditional age-based formula (Duracher's formula : age / 4 + 3.5)\n",
    "y_cuff_trad = np.array([math.floor((math.floor(age) / 4 + 3.5) * 2) / 2 if age >= 2 else (3.0 if age < 1 else 3.5) for age in x_cuff_test[:,0]], dtype=float)\n",
    "\n",
    "# Get the length of the test data\n",
    "total = len(x_cuff_test)\n",
    "\n",
    "# Lists to store results from bootstrapping\n",
    "y1_trads, y2_trads, f1_trads = [], [], []\n",
    "runs = 10000   # Number of bootstrap runs\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(runs):\n",
    "    # Sample random indexes with replacement\n",
    "    ind = np.random.randint(total, size=total)\n",
    "    \n",
    "    # Create bootstrap samples for features and labels\n",
    "    boot_x = x_cuff_test[ind]\n",
    "    boot_y = y_cuff_test[ind]\n",
    "    \n",
    "    # Get the corresponding predictions from the traditional formula for bootstrapped samples\n",
    "    y_trad = y_cuff_trad[ind]\n",
    "    \n",
    "    # Round the predicted values to the nearest 0.5 mm\n",
    "    y_trad = np.round(y_trad * 2) / 2\n",
    "    \n",
    "    # Calculate and store accuracy metrics for the bootstrapped samples\n",
    "    y1_trads.append(np.mean(y_trad == boot_y))  # Accuracy of predicting exact ETT size\n",
    "    y2_trads.append(np.mean((y_trad >= boot_y - 0.5) & (y_trad <= boot_y + 0.5))) # Accuracy within tolerance of 0.5mm \n",
    "    yl_test = np.array([f'{i}' for i in boot_y])  # Convert true labels to string for f1_score calculation\n",
    "    yl_pred = np.array([f'{i}' for i in y_trad])  # Convert predicted labels to string for f1_score calculation\n",
    "    f1_trads.append(f1_score(yl_test, yl_pred, average='macro'))  # Calculate and store macro-averaged F1 score for each bootstrapped sample\n",
    "    \n",
    "# Print the results of the bootstrapping for the traditional formula for cuffed ETT\n",
    "print('traditional formula for cuffed ETT (Duracher)')\n",
    "print(f'acc: {np.mean(y1_trads):.3f}+-{np.std(y1_trads):.3f}, 95% CI {np.percentile(y1_trads, 5):.3f}-{np.percentile(y1_trads, 95):.3f}')\n",
    "print(f'acc within 0.5mm: {np.mean(y2_trads):.3f}+-{np.std(y2_trads):.3f}, 95% CI {np.percentile(y2_trads, 5):.3f}-{np.percentile(y2_trads, 95):.3f}')\n",
    "print(f'macro f1: {np.mean(f1_trads):.3f}+-{np.std(f1_trads):.3f}, 95% CI {np.percentile(f1_trads, 5):.3f}-{np.percentile(f1_trads, 95):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ea229-db4d-4bfe-8812-90ef0d0aa53e",
   "metadata": {},
   "source": [
    "### Uncuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d17571d-3599-440a-88bc-9daf3bbe259c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:41:34.337803Z",
     "iopub.status.busy": "2023-08-01T07:41:34.337528Z",
     "iopub.status.idle": "2023-08-01T07:44:35.255046Z",
     "shell.execute_reply": "2023-08-01T07:44:35.254420Z",
     "shell.execute_reply.started": "2023-08-01T07:41:34.337778Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traditional formula for uncuffed ETT (Cole)\n",
      "acc: 0.203+-0.006, 95% CI 0.193-0.212\n",
      "acc within 0.5mm: 0.781+-0.006, 95% CI 0.771-0.791\n",
      "macro f1: 0.164+-0.018, 95% CI 0.140-0.196\n"
     ]
    }
   ],
   "source": [
    "# Traditional age-based formula (Cole's formula : age / 4 + 4)\n",
    "y_uncuff_trad1 = np.array([math.floor((math.floor(age) / 4 + 4) * 2) / 2 if age >= 2 else (3.5 if age < 1 else 4) for age in x_uncuff_test[:,0]], dtype=float)\n",
    "\n",
    "# Get the length of the test data\n",
    "total = len(x_uncuff_test)\n",
    "\n",
    "# Lists to store results from bootstrapping\n",
    "y1_trads, y2_trads, f1_trads = [], [], []\n",
    "runs = 10000   # Number of bootstrap runs\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(runs):\n",
    "    # Sample random indexes with replacement\n",
    "    ind = np.random.randint(total, size=total)\n",
    "    \n",
    "    # Create bootstrap samples for features and labels\n",
    "    boot_x = x_uncuff_test[ind]\n",
    "    boot_y = y_uncuff_test[ind]\n",
    "    \n",
    "    # Get the corresponding predictions from the traditional formula for bootstrapped samples\n",
    "    y_trad = y_uncuff_trad1[ind]\n",
    "    \n",
    "    # Round the predicted values to the nearest 0.5 mm\n",
    "    y_trad = np.round(y_trad * 2) / 2\n",
    "    \n",
    "    # Calculate and store accuracy metrics for the bootstrapped samples\n",
    "    y1_trads.append(np.mean(y_trad == boot_y))  # Accuracy of predicting exact ETT size\n",
    "    y2_trads.append(np.mean((y_trad >= boot_y - 0.5) & (y_trad <= boot_y + 0.5))) # Accuracy within tolerance of 0.5mm \n",
    "    yl_test = np.array([f'{i}' for i in boot_y])  # Convert true labels to string for f1_score calculation\n",
    "    yl_pred = np.array([f'{i}' for i in y_trad])  # Convert predicted labels to string for f1_score calculation\n",
    "    f1_trads.append(f1_score(yl_test, yl_pred, average='macro'))  # Calculate and store macro-averaged F1 score for each bootstrapped sample\n",
    "    \n",
    "# Print the results of the bootstrapping for the traditional formula for uncuffed ETT\n",
    "print('traditional formula for uncuffed ETT (Cole)')\n",
    "print(f'acc: {np.mean(y1_trads):.3f}+-{np.std(y1_trads):.3f}, 95% CI {np.percentile(y1_trads, 5):.3f}-{np.percentile(y1_trads, 95):.3f}')\n",
    "print(f'acc within 0.5mm: {np.mean(y2_trads):.3f}+-{np.std(y2_trads):.3f}, 95% CI {np.percentile(y2_trads, 5):.3f}-{np.percentile(y2_trads, 95):.3f}')\n",
    "print(f'macro f1: {np.mean(f1_trads):.3f}+-{np.std(f1_trads):.3f}, 95% CI {np.percentile(f1_trads, 5):.3f}-{np.percentile(f1_trads, 95):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340ef677-3832-4e1d-ab10-39b905d7bba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:44:35.256252Z",
     "iopub.status.busy": "2023-08-01T07:44:35.255986Z",
     "iopub.status.idle": "2023-08-01T07:47:34.590958Z",
     "shell.execute_reply": "2023-08-01T07:47:34.590289Z",
     "shell.execute_reply.started": "2023-08-01T07:44:35.256228Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* traditional formula for uncuffed ETT (Penlington)\n",
      "acc: 0.413+-0.007, 95% CI 0.402-0.425\n",
      "acc within 0.5mm: 0.826+-0.006, 95% CI 0.817-0.835\n",
      "macro f1: 0.203+-0.004, 95% CI 0.196-0.211\n"
     ]
    }
   ],
   "source": [
    "# Traditional age-based formula (Penlington's formula : age / 4 + 4.5)\n",
    "y_uncuff_trad2 = np.array([math.floor((math.floor(age) / 4 + 4.5) * 2) / 2 if age < 6.5 else math.floor((math.floor(age) / 3 + 3.5) * 2) / 2 for age in x_uncuff_test[:,0]], dtype=float)\n",
    "\n",
    "# Get the length of the test data\n",
    "total = len(x_uncuff_test)\n",
    "\n",
    "# Lists to store results from bootstrapping\n",
    "y1_trads, y2_trads, f1_trads = [], [], []\n",
    "runs = 10000   # Number of bootstrap runs\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(runs):\n",
    "    # Sample random indexes with replacement\n",
    "    ind = np.random.randint(total, size=total)\n",
    "    \n",
    "    # Create bootstrap samples for features and labels\n",
    "    boot_x = x_uncuff_test[ind]\n",
    "    boot_y = y_uncuff_test[ind]\n",
    "    \n",
    "    # Get the corresponding predictions from the traditional formula for bootstrapped samples\n",
    "    y_trad = y_uncuff_trad2[ind]\n",
    "    \n",
    "    # Round the predicted values to the nearest 0.5 mm\n",
    "    y_trad = np.round(y_trad * 2) / 2\n",
    "    \n",
    "    # Calculate and store accuracy metrics for the bootstrapped samples\n",
    "    y1_trads.append(np.mean(y_trad == boot_y))  # Accuracy of predicting exact ETT size\n",
    "    y2_trads.append(np.mean((y_trad >= boot_y - 0.5) & (y_trad <= boot_y + 0.5))) # Accuracy within tolerance of 0.5mm \n",
    "    yl_test = np.array([f'{i}' for i in boot_y])  # Convert true labels to string for f1_score calculation\n",
    "    yl_pred = np.array([f'{i}' for i in y_trad])  # Convert predicted labels to string for f1_score calculation\n",
    "    f1_trads.append(f1_score(yl_test, yl_pred, average='macro'))  # Calculate and store macro-averaged F1 score for each bootstrapped sample\n",
    "    \n",
    "# Print the results of the bootstrapping for the traditional formula for uncuffed ETT\n",
    "print('* traditional formula for uncuffed ETT (Penlington)')\n",
    "print(f'acc: {np.mean(y1_trads):.3f}+-{np.std(y1_trads):.3f}, 95% CI {np.percentile(y1_trads, 5):.3f}-{np.percentile(y1_trads, 95):.3f}')\n",
    "print(f'acc within 0.5mm: {np.mean(y2_trads):.3f}+-{np.std(y2_trads):.3f}, 95% CI {np.percentile(y2_trads, 5):.3f}-{np.percentile(y2_trads, 95):.3f}')\n",
    "print(f'macro f1: {np.mean(f1_trads):.3f}+-{np.std(f1_trads):.3f}, 95% CI {np.percentile(f1_trads, 5):.3f}-{np.percentile(f1_trads, 95):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3618f4-3975-40df-8fb3-f54d4c547437",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31d585-0970-4c69-aa9f-ede738418e26",
   "metadata": {},
   "source": [
    "### Cuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b92ff88-1513-4543-bdad-bc9cf7c6c3b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:47:34.592648Z",
     "iopub.status.busy": "2023-08-01T07:47:34.592385Z",
     "iopub.status.idle": "2023-08-01T07:47:34.601395Z",
     "shell.execute_reply": "2023-08-01T07:47:34.600628Z",
     "shell.execute_reply.started": "2023-08-01T07:47:34.592624Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression model\n",
      "coefficient [0.21243728 0.00857616], intercept 3.558\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Create a Linear Regression model for cuffed endotracheal tube data\n",
    "lr_cuff = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_cuff.fit(x_cuff_train, y_cuff_train)\n",
    "\n",
    "# Make predictions on the test data using the trained model\n",
    "y_pred = lr_cuff.predict(x_cuff_test)\n",
    "\n",
    "# Round the predicted values to the nearest 0.5 mm\n",
    "y_pred = np.round(y_pred * 2) / 2\n",
    "\n",
    "# Print the results for the Linear Regression model\n",
    "print('linear regression model')\n",
    "print(f'coefficient {lr_cuff.coef_}, intercept {lr_cuff.intercept_:.3f}')\n",
    "print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14bbc6b6-fc70-428f-ad29-769642b4abbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:47:34.602647Z",
     "iopub.status.busy": "2023-08-01T07:47:34.602414Z",
     "iopub.status.idle": "2023-08-01T07:49:26.446436Z",
     "shell.execute_reply": "2023-08-01T07:49:26.445778Z",
     "shell.execute_reply.started": "2023-08-01T07:47:34.602617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* linear regression model for cuffed ETT\n",
      "acc: 0.571+-0.010, 95% CI 0.555-0.587\n",
      "acc within 0.5mm: 0.990+-0.002, 95% CI 0.987-0.993\n",
      "macro f1: 0.554+-0.013, 95% CI 0.533-0.576\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the test data\n",
    "total = len(x_cuff_test)\n",
    "\n",
    "# Lists to store results from bootstrapping\n",
    "y1_lrs, y2_lrs, f1_lrs = [], [], []\n",
    "runs = 10000   # Number of bootstrap runs\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(runs):\n",
    "    # Sample random indexes with replacement\n",
    "    ind = np.random.randint(total, size=total)\n",
    "    \n",
    "    # Create bootstrap samples for features and labels\n",
    "    boot_x = x_cuff_test[ind]\n",
    "    boot_y = y_cuff_test[ind]\n",
    "    \n",
    "    # Calculate the prediction of linear regression model\n",
    "    y_lr = lr_cuff.predict(boot_x)\n",
    "    \n",
    "    # Round the predicted values to the nearest 0.5 mm\n",
    "    y_lr = np.round(y_lr * 2) / 2\n",
    "    \n",
    "    # Calculate and store accuracy metrics for the bootstrapped samples\n",
    "    y1_lrs.append(np.mean(y_lr == boot_y))  # Accuracy of predicting exact ETT size\n",
    "    y2_lrs.append(np.mean((y_lr >= boot_y - 0.5) & (y_lr <= boot_y + 0.5))) # Accuracy within tolerance of 0.5mm \n",
    "    yl_test = np.array([f'{i}' for i in boot_y])  # Convert true labels to string for f1_score calculation\n",
    "    yl_pred = np.array([f'{i}' for i in y_lr])  # Convert predicted labels to string for f1_score calculation\n",
    "    f1_lrs.append(f1_score(yl_test, yl_pred, average='macro'))  # Calculate and store macro-averaged F1 score for each bootstrapped sample\n",
    "    \n",
    "# Print the results of the bootstrapping for the linear regression model for cuffed ETT\n",
    "print('* linear regression model for cuffed ETT')\n",
    "print(f'acc: {np.mean(y1_lrs):.3f}+-{np.std(y1_lrs):.3f}, 95% CI {np.percentile(y1_lrs, 5):.3f}-{np.percentile(y1_lrs, 95):.3f}')\n",
    "print(f'acc within 0.5mm: {np.mean(y2_lrs):.3f}+-{np.std(y2_lrs):.3f}, 95% CI {np.percentile(y2_lrs, 5):.3f}-{np.percentile(y2_lrs, 95):.3f}')\n",
    "print(f'macro f1: {np.mean(f1_lrs):.3f}+-{np.std(f1_lrs):.3f}, 95% CI {np.percentile(f1_lrs, 5):.3f}-{np.percentile(f1_lrs, 95):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d4436-08d2-47cc-9e6b-450fde18ff98",
   "metadata": {},
   "source": [
    "### Uncuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c81811-a456-481b-857b-8c9dc5b7f27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:49:26.447570Z",
     "iopub.status.busy": "2023-08-01T07:49:26.447319Z",
     "iopub.status.idle": "2023-08-01T07:49:26.456496Z",
     "shell.execute_reply": "2023-08-01T07:49:26.455734Z",
     "shell.execute_reply.started": "2023-08-01T07:49:26.447546Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression model\n",
      "coefficient [0.22728641 0.03159429], intercept 3.608\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Create a Linear Regression model for uncuffed endotracheal tube data\n",
    "lr_uncuff = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_uncuff.fit(x_uncuff_train, y_uncuff_train)\n",
    "\n",
    "# Make predictions on the test data using the trained model\n",
    "y_pred = lr_uncuff.predict(x_uncuff_test)\n",
    "\n",
    "# Round the predicted values to the nearest 0.5 mm\n",
    "y_pred = np.round(y_pred * 2) / 2\n",
    "\n",
    "# Print the results for the Linear Regression model\n",
    "print('linear regression model')\n",
    "print(f'coefficient {lr_uncuff.coef_}, intercept {lr_uncuff.intercept_:.3f}')\n",
    "print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67bd835-d29a-4c9d-966f-8bc370de2d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:49:26.457740Z",
     "iopub.status.busy": "2023-08-01T07:49:26.457494Z",
     "iopub.status.idle": "2023-08-01T07:52:28.189902Z",
     "shell.execute_reply": "2023-08-01T07:52:28.189226Z",
     "shell.execute_reply.started": "2023-08-01T07:49:26.457709Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* linear regression model for uncuffed ETT\n",
      "acc: 0.409+-0.007, 95% CI 0.398-0.421\n",
      "acc within 0.5mm: 0.937+-0.004, 95% CI 0.931-0.943\n",
      "macro f1: 0.221+-0.005, 95% CI 0.213-0.229\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the test data\n",
    "total = len(x_uncuff_test)\n",
    "\n",
    "# Lists to store results from bootstrapping\n",
    "y1_lrs, y2_lrs, f1_lrs = [], [], []\n",
    "runs = 10000   # Number of bootstrap runs\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(runs):\n",
    "    # Sample random indexes with replacement\n",
    "    ind = np.random.randint(total, size=total)\n",
    "    \n",
    "    # Create bootstrap samples for features and labels\n",
    "    boot_x = x_uncuff_test[ind]\n",
    "    boot_y = y_uncuff_test[ind]\n",
    "    \n",
    "    # Calculate the prediction of linear regression model\n",
    "    y_lr = lr_uncuff.predict(boot_x)\n",
    "    \n",
    "    # Round the predicted values to the nearest 0.5 mm\n",
    "    y_lr = np.round(y_lr * 2) / 2\n",
    "    \n",
    "    # Calculate and store accuracy metrics for the bootstrapped samples\n",
    "    y1_lrs.append(np.mean(y_lr == boot_y))  # Accuracy of predicting exact ETT size\n",
    "    y2_lrs.append(np.mean((y_lr >= boot_y - 0.5) & (y_lr <= boot_y + 0.5))) # Accuracy within tolerance of 0.5mm \n",
    "    yl_test = np.array([f'{i}' for i in boot_y])  # Convert true labels to string for f1_score calculation\n",
    "    yl_pred = np.array([f'{i}' for i in y_lr])  # Convert predicted labels to string for f1_score calculation\n",
    "    f1_lrs.append(f1_score(yl_test, yl_pred, average='macro'))  # Calculate and store macro-averaged F1 score for each bootstrapped sample\n",
    "    \n",
    "# Print the results of the bootstrapping for the linear regression model for cuffed ETT\n",
    "print('* linear regression model for uncuffed ETT')\n",
    "print(f'acc: {np.mean(y1_lrs):.3f}+-{np.std(y1_lrs):.3f}, 95% CI {np.percentile(y1_lrs, 5):.3f}-{np.percentile(y1_lrs, 95):.3f}')\n",
    "print(f'acc within 0.5mm: {np.mean(y2_lrs):.3f}+-{np.std(y2_lrs):.3f}, 95% CI {np.percentile(y2_lrs, 5):.3f}-{np.percentile(y2_lrs, 95):.3f}')\n",
    "print(f'macro f1: {np.mean(f1_lrs):.3f}+-{np.std(f1_lrs):.3f}, 95% CI {np.percentile(f1_lrs, 5):.3f}-{np.percentile(f1_lrs, 95):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e394388-a458-4778-b23d-1a86d0a5ad19",
   "metadata": {},
   "source": [
    "## Gradient-boosted regression tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb834d57-3987-4a17-bddf-4d247a02253e",
   "metadata": {},
   "source": [
    "### Cuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49cd4257-75cf-45ed-a281-76271342fcb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:52:28.191068Z",
     "iopub.status.busy": "2023-08-01T07:52:28.190806Z",
     "iopub.status.idle": "2023-08-01T07:59:02.441232Z",
     "shell.execute_reply": "2023-08-01T07:59:02.440358Z",
     "shell.execute_reply.started": "2023-08-01T07:52:28.191045Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2880 candidates, totalling 28800 fits\n",
      "\n",
      "========= found hyperparameter =========\n",
      "{'colsample_bytree': 1, 'gamma': 0.5, 'learning_rate': 0.07, 'max_depth': 5, 'n_estimators': 300, 'subsample': 1}\n",
      "0.8739470228761033\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# age (일단위)\n",
    "param_dict = {\n",
    "                'learning_rate': [ 0.01, 0.03, 0.05, 0.07], #, #[0.01, 0.03, 0.05],\n",
    "                'max_depth': [3, 4, 5, 7],#[3,4,5],\n",
    "                'n_estimators': [25, 50, 75, 100, 300],\n",
    "                'subsample': [0.5, 0.8, 1], #[0.5, 0.8, 1],\n",
    "                'colsample_bytree': [0.5, 0.8, 1], #[0.8, 1],\n",
    "                'gamma': [0.3, 0.5, 0.7, 0.9],\n",
    "            }\n",
    "nfold = 10\n",
    "gs = GridSearchCV(estimator=xgb.sklearn.XGBRegressor(),\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                param_grid=param_dict, cv=nfold)\n",
    "gs.fit(x_cuff_train, y_cuff_train)\n",
    "\n",
    "print()\n",
    "print(\"========= found hyperparameter =========\")\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "print(\"========================================\")\n",
    "\n",
    "gbrt_cuff = gs.best_estimator_.get_booster()\n",
    "\n",
    "y_pred = gbrt_cuff.predict(xgb.DMatrix(x_cuff_test)).flatten()\n",
    "y_pred = np.round(y_pred * 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a6a0f9-daf5-4b3c-9c25-bda36ccffd25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T07:59:02.443617Z",
     "iopub.status.busy": "2023-08-01T07:59:02.443049Z",
     "iopub.status.idle": "2023-08-01T08:03:07.794922Z",
     "shell.execute_reply": "2023-08-01T08:03:07.794076Z",
     "shell.execute_reply.started": "2023-08-01T07:59:02.443580Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* gradient-boosted regression tree model for cuffed ETT\n",
      "acc: 0.701+-0.009, 95% CI 0.686-0.715\n",
      "acc within 0.5mm: 0.995+-0.001, 95% CI 0.993-0.997\n",
      "macro f1: 0.607+-0.008, 95% CI 0.594-0.620\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the test data\n",
    "total = len(x_cuff_test)\n",
    "\n",
    "# Lists to store results from bootstrapping\n",
    "y1_gbrts, y2_gbrts, f1_gbrts = [], [], []\n",
    "runs = 10000   # Number of bootstrap runs\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(runs):\n",
    "    # Sample random indexes with replacement\n",
    "    ind = np.random.randint(total, size=total)\n",
    "    \n",
    "    # Create bootstrap samples for features and labels\n",
    "    boot_x = x_cuff_test[ind]\n",
    "    boot_y = y_cuff_test[ind]\n",
    "    \n",
    "    # Calculate the prediction of linear regression model\n",
    "    y_gbrt = gbrt_cuff.predict(xgb.DMatrix(boot_x))\n",
    "    \n",
    "    # Round the predicted values to the nearest 0.5 mm\n",
    "    y_gbrt = np.round(y_gbrt * 2) / 2\n",
    "    \n",
    "    # Calculate and store accuracy metrics for the bootstrapped samples\n",
    "    y1_gbrts.append(np.mean(y_gbrt == boot_y))  # Accuracy of predicting exact ETT size\n",
    "    y2_gbrts.append(np.mean((y_gbrt >= boot_y - 0.5) & (y_gbrt <= boot_y + 0.5))) # Accuracy within tolerance of 0.5mm \n",
    "    yl_test = np.array([f'{i}' for i in boot_y])  # Convert true labels to string for f1_score calculation\n",
    "    yl_pred = np.array([f'{i}' for i in y_gbrt])  # Convert predicted labels to string for f1_score calculation\n",
    "    f1_gbrts.append(f1_score(yl_test, yl_pred, average='macro'))  # Calculate and store macro-averaged F1 score for each bootstrapped sample\n",
    "    \n",
    "# Print the results of the bootstrapping for the gradient-boosted regression tree model for cuffed ETT\n",
    "print('* gradient-boosted regression tree model for cuffed ETT')\n",
    "print(f'acc: {np.mean(y1_gbrts):.3f}+-{np.std(y1_gbrts):.3f}, 95% CI {np.percentile(y1_gbrts, 5):.3f}-{np.percentile(y1_gbrts, 95):.3f}')\n",
    "print(f'acc within 0.5mm: {np.mean(y2_gbrts):.3f}+-{np.std(y2_gbrts):.3f}, 95% CI {np.percentile(y2_gbrts, 5):.3f}-{np.percentile(y2_gbrts, 95):.3f}')\n",
    "print(f'macro f1: {np.mean(f1_gbrts):.3f}+-{np.std(f1_gbrts):.3f}, 95% CI {np.percentile(f1_gbrts, 5):.3f}-{np.percentile(f1_gbrts, 95):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70720d43-66b9-4e67-8b3e-a7720bc6ec4c",
   "metadata": {},
   "source": [
    "### Uncuffed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb1f440-e29e-4b8f-97d9-4c820a96e717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T08:03:07.840083Z",
     "iopub.status.busy": "2023-08-01T08:03:07.839624Z",
     "iopub.status.idle": "2023-08-01T08:13:53.258150Z",
     "shell.execute_reply": "2023-08-01T08:13:53.257423Z",
     "shell.execute_reply.started": "2023-08-01T08:03:07.840050Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2880 candidates, totalling 28800 fits\n",
      "\n",
      "========= found hyperparameter =========\n",
      "{'colsample_bytree': 1, 'gamma': 0.9, 'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.8}\n",
      "0.8918211310847501\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# age (일단위)\n",
    "param_dict = {\n",
    "                'learning_rate': [ 0.01, 0.03, 0.05, 0.07], #, #[0.01, 0.03, 0.05],\n",
    "                'max_depth': [3, 4, 5, 7],#[3,4,5],\n",
    "                'n_estimators': [25, 50, 75, 100, 300],\n",
    "                'subsample': [0.5, 0.8, 1], #[0.5, 0.8, 1],\n",
    "                'colsample_bytree': [0.5, 0.8, 1], #[0.8, 1],\n",
    "                'gamma': [0.3, 0.5, 0.7, 0.9],\n",
    "            }\n",
    "nfold = 10\n",
    "gs = GridSearchCV(estimator=xgb.sklearn.XGBRegressor(),\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                param_grid=param_dict, cv=nfold)\n",
    "gs.fit(x_uncuff_train, y_uncuff_train)\n",
    "\n",
    "print()\n",
    "print(\"========= found hyperparameter =========\")\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "print(\"========================================\")\n",
    "\n",
    "gbrt_uncuff = gs.best_estimator_.get_booster()\n",
    "\n",
    "y_pred = gbrt_uncuff.predict(xgb.DMatrix(x_uncuff_test)).flatten()\n",
    "y_pred = np.round(y_pred * 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80350285-932a-43b4-ad8f-54da3a412b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T08:13:53.260014Z",
     "iopub.status.busy": "2023-08-01T08:13:53.259533Z",
     "iopub.status.idle": "2023-08-01T08:20:37.372517Z",
     "shell.execute_reply": "2023-08-01T08:20:37.371799Z",
     "shell.execute_reply.started": "2023-08-01T08:13:53.259979Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* gradient-boosted regression tree model for uncuffed ETT\n",
      "acc: 0.581+-0.007, 95% CI 0.569-0.592\n",
      "acc within 0.5mm: 0.983+-0.002, 95% CI 0.980-0.986\n",
      "macro f1: 0.514+-0.031, 95% CI 0.482-0.562\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the test data\n",
    "total = len(x_uncuff_test)\n",
    "\n",
    "# Lists to store results from bootstrapping\n",
    "y1_gbrts, y2_gbrts, f1_gbrts = [], [], []\n",
    "runs = 10000   # Number of bootstrap runs\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(runs):\n",
    "    # Sample random indexes with replacement\n",
    "    ind = np.random.randint(total, size=total)\n",
    "    \n",
    "    # Create bootstrap samples for features and labels\n",
    "    boot_x = x_uncuff_test[ind]\n",
    "    boot_y = y_uncuff_test[ind]\n",
    "    \n",
    "    # Calculate the prediction of linear regression model\n",
    "    y_gbrt = gbrt_uncuff.predict(xgb.DMatrix(boot_x))\n",
    "    \n",
    "    # Round the predicted values to the nearest 0.5 mm\n",
    "    y_gbrt = np.round(y_gbrt * 2) / 2\n",
    "    \n",
    "    # Calculate and store accuracy metrics for the bootstrapped samples\n",
    "    y1_gbrts.append(np.mean(y_gbrt == boot_y))  # Accuracy of predicting exact ETT size\n",
    "    y2_gbrts.append(np.mean((y_gbrt >= boot_y - 0.5) & (y_gbrt <= boot_y + 0.5))) # Accuracy within tolerance of 0.5mm \n",
    "    yl_test = np.array([f'{i}' for i in boot_y])  # Convert true labels to string for f1_score calculation\n",
    "    yl_pred = np.array([f'{i}' for i in y_gbrt])  # Convert predicted labels to string for f1_score calculation\n",
    "    f1_gbrts.append(f1_score(yl_test, yl_pred, average='macro'))  # Calculate and store macro-averaged F1 score for each bootstrapped sample\n",
    "    \n",
    "# Print the results of the bootstrapping for the gradient-boosted regression tree model for cuffed ETT\n",
    "print('* gradient-boosted regression tree model for uncuffed ETT')\n",
    "print(f'acc: {np.mean(y1_gbrts):.3f}+-{np.std(y1_gbrts):.3f}, 95% CI {np.percentile(y1_gbrts, 5):.3f}-{np.percentile(y1_gbrts, 95):.3f}')\n",
    "print(f'acc within 0.5mm: {np.mean(y2_gbrts):.3f}+-{np.std(y2_gbrts):.3f}, 95% CI {np.percentile(y2_gbrts, 5):.3f}-{np.percentile(y2_gbrts, 95):.3f}')\n",
    "print(f'macro f1: {np.mean(f1_gbrts):.3f}+-{np.std(f1_gbrts):.3f}, 95% CI {np.percentile(f1_gbrts, 5):.3f}-{np.percentile(f1_gbrts, 95):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "painstudy_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
